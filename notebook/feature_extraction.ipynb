{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:47:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import fairseq \n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/MLAlgos/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): ConvFeatureExtractionModel(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Sequential(\n",
       "          (0): TransposeLast()\n",
       "          (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): TransposeLast()\n",
       "        )\n",
       "        (3): GELU(approximate='none')\n",
       "      )\n",
       "      (1-4): 4 x Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Sequential(\n",
       "          (0): TransposeLast()\n",
       "          (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): TransposeLast()\n",
       "        )\n",
       "        (3): GELU(approximate='none')\n",
       "      )\n",
       "      (5-6): 2 x Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Sequential(\n",
       "          (0): TransposeLast()\n",
       "          (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): TransposeLast()\n",
       "        )\n",
       "        (3): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "  (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "  (quantizer): GumbelVectorQuantizer(\n",
       "    (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "  )\n",
       "  (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([str(Path.home())+'/Daniyal/profanity_detection/model/kannada_pretrained_1400h.pt'])\n",
    "model = model[0]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset (Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd. read_csv (csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "\n",
    "        # 16000 * 30\n",
    "        file_path = os.path.join(self. root_dir, self.annotations. iloc[index, 0])\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "\n",
    "        #waveform= truncate_or_pad_waveform(waveform, target_length=100000)\n",
    "        \n",
    "        if self .annotations. iloc [index, 1]=='Yes':\n",
    "            y_label = torch. tensor(1)\n",
    "        else:\n",
    "            y_label = torch. tensor (0)\n",
    "        \n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        \n",
    "        \n",
    "        waveform=model.feature_extractor(waveform)\n",
    "        #max_pool, _ = torch.max(waveform, dim=2)\n",
    "\n",
    "        return (waveform,self.annotations. iloc[index, 0], y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_test_dataset = AudioDataset (csv_file = '/home/ubuntu/Daniyal/profanity_detection/data/Hindi_test.csv', root_dir = \"/home/ubuntu/Daniyal/profanity_detection/data/Prima/SC_audio_Hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_train_loader = DataLoader (dataset=hindi_test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) ('Abuse_1197.wav',)\n",
      "tensor([0]) ('Abuse_589.wav',)\n",
      "tensor([0]) ('Abuse_327.wav',)\n",
      "tensor([0]) ('Abuse_800.wav',)\n",
      "tensor([0]) ('Abuse_1179.wav',)\n",
      "tensor([0]) ('Abuse_714.wav',)\n",
      "tensor([1]) ('Abuse_295.wav',)\n",
      "tensor([1]) ('Abuse_335.wav',)\n",
      "tensor([1]) ('Abuse_490.wav',)\n",
      "tensor([1]) ('Abuse_889.wav',)\n",
      "tensor([1]) ('Abuse_475.wav',)\n",
      "tensor([0]) ('Abuse_176.wav',)\n",
      "tensor([0]) ('Abuse_1171.wav',)\n",
      "tensor([1]) ('Abuse_942.wav',)\n",
      "tensor([1]) ('Abuse_14.wav',)\n",
      "tensor([0]) ('Abuse_439.wav',)\n",
      "tensor([1]) ('Abuse_864.wav',)\n",
      "tensor([0]) ('Abuse_477.wav',)\n",
      "tensor([1]) ('Abuse_134.wav',)\n",
      "tensor([1]) ('Abuse_783.wav',)\n",
      "tensor([0]) ('Abuse_424.wav',)\n",
      "tensor([1]) ('Abuse_1062.wav',)\n",
      "tensor([0]) ('Abuse_731.wav',)\n",
      "tensor([0]) ('Abuse_1098.wav',)\n",
      "tensor([0]) ('Abuse_646.wav',)\n",
      "tensor([0]) ('Abuse_286.wav',)\n",
      "tensor([1]) ('Abuse_168.wav',)\n",
      "tensor([1]) ('Abuse_272.wav',)\n",
      "tensor([1]) ('Abuse_270.wav',)\n",
      "tensor([0]) ('Abuse_756.wav',)\n",
      "tensor([1]) ('Abuse_921.wav',)\n",
      "tensor([1]) ('Abuse_118.wav',)\n",
      "tensor([1]) ('Abuse_1020.wav',)\n",
      "tensor([0]) ('Abuse_924.wav',)\n",
      "tensor([0]) ('Abuse_315.wav',)\n",
      "tensor([1]) ('Abuse_105.wav',)\n",
      "tensor([0]) ('Abuse_797.wav',)\n",
      "tensor([1]) ('Abuse_435.wav',)\n",
      "tensor([1]) ('Abuse_1094.wav',)\n",
      "tensor([1]) ('Abuse_562.wav',)\n",
      "tensor([0]) ('Abuse_173.wav',)\n",
      "tensor([0]) ('Abuse_719.wav',)\n",
      "tensor([0]) ('Abuse_768.wav',)\n",
      "tensor([0]) ('Abuse_1173.wav',)\n",
      "tensor([1]) ('Abuse_668.wav',)\n",
      "tensor([0]) ('Abuse_582.wav',)\n",
      "tensor([0]) ('Abuse_1056.wav',)\n",
      "tensor([1]) ('Abuse_566.wav',)\n",
      "tensor([1]) ('Abuse_1012.wav',)\n",
      "tensor([0]) ('Abuse_647.wav',)\n",
      "tensor([1]) ('Abuse_1158.wav',)\n",
      "tensor([0]) ('Abuse_47.wav',)\n",
      "tensor([0]) ('Abuse_687.wav',)\n",
      "tensor([1]) ('Abuse_415.wav',)\n",
      "tensor([0]) ('Abuse_478.wav',)\n",
      "tensor([1]) ('Abuse_221.wav',)\n",
      "tensor([0]) ('Abuse_753.wav',)\n",
      "tensor([0]) ('Abuse_1188.wav',)\n",
      "tensor([0]) ('Abuse_986.wav',)\n",
      "tensor([0]) ('Abuse_988.wav',)\n",
      "tensor([1]) ('Abuse_18.wav',)\n",
      "tensor([0]) ('Abuse_850.wav',)\n",
      "tensor([1]) ('Abuse_401.wav',)\n",
      "tensor([0]) ('Abuse_883.wav',)\n",
      "tensor([0]) ('Abuse_259.wav',)\n",
      "tensor([0]) ('Abuse_1159.wav',)\n",
      "tensor([1]) ('Abuse_1039.wav',)\n",
      "tensor([1]) ('Abuse_304.wav',)\n",
      "tensor([0]) ('Abuse_1058.wav',)\n",
      "tensor([0]) ('Abuse_674.wav',)\n",
      "tensor([1]) ('Abuse_425.wav',)\n",
      "tensor([1]) ('Abuse_818.wav',)\n",
      "tensor([0]) ('Abuse_666.wav',)\n",
      "tensor([1]) ('Abuse_804.wav',)\n",
      "tensor([1]) ('Abuse_276.wav',)\n",
      "tensor([0]) ('Abuse_603.wav',)\n",
      "tensor([1]) ('Abuse_1008.wav',)\n",
      "tensor([1]) ('Abuse_143.wav',)\n",
      "tensor([1]) ('Abuse_431.wav',)\n",
      "tensor([0]) ('Abuse_164.wav',)\n",
      "tensor([1]) ('Abuse_1176.wav',)\n",
      "tensor([1]) ('Abuse_1115.wav',)\n",
      "tensor([1]) ('Abuse_58.wav',)\n",
      "tensor([0]) ('Abuse_673.wav',)\n",
      "tensor([1]) ('Abuse_820.wav',)\n",
      "tensor([0]) ('Abuse_1078.wav',)\n",
      "tensor([1]) ('Abuse_201.wav',)\n",
      "tensor([1]) ('Abuse_959.wav',)\n",
      "tensor([0]) ('Abuse_1187.wav',)\n",
      "tensor([0]) ('Abuse_1017.wav',)\n",
      "tensor([1]) ('Abuse_826.wav',)\n",
      "tensor([1]) ('Abuse_859.wav',)\n",
      "tensor([0]) ('Abuse_688.wav',)\n",
      "tensor([1]) ('Abuse_692.wav',)\n",
      "tensor([1]) ('Abuse_463.wav',)\n",
      "tensor([0]) ('Abuse_417.wav',)\n",
      "tensor([0]) ('Abuse_676.wav',)\n",
      "tensor([0]) ('Abuse_540.wav',)\n",
      "tensor([0]) ('Abuse_780.wav',)\n",
      "tensor([1]) ('Abuse_55.wav',)\n",
      "tensor([0]) ('Abuse_705.wav',)\n",
      "tensor([0]) ('Abuse_713.wav',)\n",
      "tensor([0]) ('Abuse_19.wav',)\n",
      "tensor([0]) ('Abuse_1133.wav',)\n",
      "tensor([0]) ('Abuse_1170.wav',)\n",
      "tensor([0]) ('Abuse_740.wav',)\n",
      "tensor([1]) ('Abuse_376.wav',)\n",
      "tensor([1]) ('Abuse_846.wav',)\n",
      "tensor([0]) ('Abuse_197.wav',)\n",
      "tensor([1]) ('Abuse_622.wav',)\n",
      "tensor([1]) ('Abuse_242.wav',)\n",
      "tensor([0]) ('Abuse_314.wav',)\n",
      "tensor([1]) ('Abuse_227.wav',)\n",
      "tensor([1]) ('Abuse_1126.wav',)\n",
      "tensor([1]) ('Abuse_690.wav',)\n",
      "tensor([1]) ('Abuse_282.wav',)\n",
      "tensor([1]) ('Abuse_857.wav',)\n",
      "tensor([0]) ('Abuse_184.wav',)\n",
      "tensor([1]) ('Abuse_1127.wav',)\n",
      "tensor([1]) ('Abuse_726.wav',)\n",
      "tensor([1]) ('Abuse_636.wav',)\n",
      "tensor([1]) ('Abuse_258.wav',)\n",
      "tensor([0]) ('Abuse_678.wav',)\n",
      "tensor([1]) ('Abuse_1118.wav',)\n",
      "tensor([1]) ('Abuse_606.wav',)\n",
      "tensor([0]) ('Abuse_1036.wav',)\n",
      "tensor([0]) ('Abuse_863.wav',)\n",
      "tensor([1]) ('Abuse_485.wav',)\n",
      "tensor([0]) ('Abuse_436.wav',)\n",
      "tensor([0]) ('Abuse_802.wav',)\n",
      "tensor([0]) ('Abuse_1015.wav',)\n",
      "tensor([1]) ('Abuse_837.wav',)\n",
      "tensor([0]) ('Abuse_801.wav',)\n",
      "tensor([1]) ('Abuse_683.wav',)\n",
      "tensor([1]) ('Abuse_653.wav',)\n",
      "tensor([1]) ('Abuse_1189.wav',)\n",
      "tensor([1]) ('Abuse_410.wav',)\n",
      "tensor([0]) ('Abuse_32.wav',)\n",
      "tensor([0]) ('Abuse_267.wav',)\n",
      "tensor([0]) ('Abuse_547.wav',)\n",
      "tensor([0]) ('Abuse_518.wav',)\n",
      "tensor([1]) ('Abuse_885.wav',)\n",
      "tensor([1]) ('Abuse_788.wav',)\n",
      "tensor([0]) ('Abuse_52.wav',)\n",
      "tensor([0]) ('Abuse_283.wav',)\n",
      "tensor([1]) ('Abuse_1114.wav',)\n",
      "tensor([1]) ('Abuse_608.wav',)\n",
      "tensor([1]) ('Abuse_667.wav',)\n",
      "tensor([0]) ('Abuse_457.wav',)\n",
      "tensor([1]) ('Abuse_41.wav',)\n",
      "tensor([0]) ('Abuse_914.wav',)\n",
      "tensor([1]) ('Abuse_604.wav',)\n",
      "tensor([1]) ('Abuse_761.wav',)\n",
      "tensor([1]) ('Abuse_171.wav',)\n",
      "tensor([1]) ('Abuse_450.wav',)\n",
      "tensor([1]) ('Abuse_1088.wav',)\n",
      "tensor([0]) ('Abuse_269.wav',)\n",
      "tensor([0]) ('Abuse_1038.wav',)\n",
      "tensor([0]) ('Abuse_1074.wav',)\n",
      "tensor([0]) ('Abuse_1191.wav',)\n",
      "tensor([0]) ('Abuse_7.wav',)\n",
      "tensor([1]) ('Abuse_523.wav',)\n",
      "tensor([1]) ('Abuse_0.wav',)\n",
      "tensor([1]) ('Abuse_650.wav',)\n",
      "tensor([0]) ('Abuse_432.wav',)\n",
      "tensor([1]) ('Abuse_896.wav',)\n",
      "tensor([1]) ('Abuse_472.wav',)\n",
      "tensor([0]) ('Abuse_232.wav',)\n",
      "tensor([1]) ('Abuse_252.wav',)\n",
      "tensor([0]) ('Abuse_96.wav',)\n",
      "tensor([1]) ('Abuse_1073.wav',)\n",
      "tensor([0]) ('Abuse_926.wav',)\n",
      "tensor([0]) ('Abuse_1117.wav',)\n",
      "tensor([0]) ('Abuse_312.wav',)\n",
      "tensor([1]) ('Abuse_711.wav',)\n",
      "tensor([0]) ('Abuse_211.wav',)\n",
      "tensor([0]) ('Abuse_512.wav',)\n",
      "tensor([1]) ('Abuse_185.wav',)\n",
      "tensor([0]) ('Abuse_343.wav',)\n",
      "tensor([1]) ('Abuse_395.wav',)\n",
      "tensor([0]) ('Abuse_617.wav',)\n",
      "tensor([1]) ('Abuse_515.wav',)\n",
      "tensor([0]) ('Abuse_377.wav',)\n",
      "tensor([1]) ('Abuse_848.wav',)\n",
      "tensor([0]) ('Abuse_695.wav',)\n",
      "tensor([0]) ('Abuse_141.wav',)\n",
      "tensor([1]) ('Abuse_938.wav',)\n",
      "tensor([0]) ('Abuse_1068.wav',)\n",
      "tensor([1]) ('Abuse_153.wav',)\n",
      "tensor([1]) ('Abuse_572.wav',)\n",
      "tensor([0]) ('Abuse_351.wav',)\n",
      "tensor([1]) ('Abuse_1148.wav',)\n",
      "tensor([1]) ('Abuse_1064.wav',)\n",
      "tensor([1]) ('Abuse_458.wav',)\n",
      "tensor([0]) ('Abuse_409.wav',)\n",
      "tensor([0]) ('Abuse_464.wav',)\n",
      "tensor([1]) ('Abuse_511.wav',)\n",
      "tensor([0]) ('Abuse_1051.wav',)\n",
      "tensor([0]) ('Abuse_413.wav',)\n",
      "tensor([1]) ('Abuse_787.wav',)\n",
      "tensor([1]) ('Abuse_467.wav',)\n",
      "tensor([0]) ('Abuse_899.wav',)\n",
      "tensor([0]) ('Abuse_599.wav',)\n",
      "tensor([0]) ('Abuse_900.wav',)\n",
      "tensor([0]) ('Abuse_762.wav',)\n",
      "tensor([1]) ('Abuse_822.wav',)\n",
      "tensor([1]) ('Abuse_357.wav',)\n",
      "tensor([1]) ('Abuse_294.wav',)\n",
      "tensor([0]) ('Abuse_925.wav',)\n",
      "tensor([0]) ('Abuse_579.wav',)\n",
      "tensor([1]) ('Abuse_145.wav',)\n",
      "tensor([1]) ('Abuse_744.wav',)\n",
      "tensor([0]) ('Abuse_121.wav',)\n",
      "tensor([1]) ('Abuse_824.wav',)\n",
      "tensor([0]) ('Abuse_897.wav',)\n",
      "tensor([1]) ('Abuse_905.wav',)\n",
      "tensor([1]) ('Abuse_268.wav',)\n",
      "tensor([1]) ('Abuse_37.wav',)\n",
      "tensor([0]) ('Abuse_794.wav',)\n",
      "tensor([0]) ('Abuse_772.wav',)\n",
      "tensor([0]) ('Abuse_817.wav',)\n",
      "tensor([0]) ('Abuse_494.wav',)\n",
      "tensor([0]) ('Abuse_397.wav',)\n",
      "tensor([0]) ('Abuse_912.wav',)\n",
      "tensor([1]) ('Abuse_1129.wav',)\n",
      "tensor([1]) ('Abuse_619.wav',)\n",
      "tensor([0]) ('Abuse_577.wav',)\n",
      "tensor([0]) ('Abuse_514.wav',)\n",
      "tensor([0]) ('Abuse_384.wav',)\n",
      "tensor([1]) ('Abuse_1132.wav',)\n",
      "tensor([1]) ('Abuse_709.wav',)\n",
      "tensor([0]) ('Abuse_779.wav',)\n",
      "tensor([0]) ('Abuse_935.wav',)\n",
      "tensor([1]) ('Abuse_1120.wav',)\n",
      "tensor([0]) ('Abuse_882.wav',)\n",
      "tensor([1]) ('Abuse_56.wav',)\n",
      "tensor([0]) ('Abuse_1141.wav',)\n",
      "tensor([0]) ('Abuse_821.wav',)\n",
      "tensor([1]) ('Abuse_170.wav',)\n",
      "tensor([0]) ('Abuse_69.wav',)\n",
      "tensor([1]) ('Abuse_16.wav',)\n",
      "tensor([1]) ('Abuse_1052.wav',)\n",
      "tensor([0]) ('Abuse_874.wav',)\n",
      "tensor([0]) ('Abuse_3.wav',)\n",
      "tensor([1]) ('Abuse_626.wav',)\n",
      "tensor([0]) ('Abuse_836.wav',)\n",
      "tensor([1]) ('Abuse_677.wav',)\n",
      "tensor([1]) ('Abuse_207.wav',)\n",
      "tensor([1]) ('Abuse_76.wav',)\n",
      "tensor([1]) ('Abuse_555.wav',)\n",
      "tensor([1]) ('Abuse_302.wav',)\n",
      "tensor([0]) ('Abuse_765.wav',)\n",
      "tensor([0]) ('Abuse_749.wav',)\n",
      "tensor([0]) ('Abuse_470.wav',)\n",
      "tensor([1]) ('Abuse_383.wav',)\n",
      "tensor([0]) ('Abuse_945.wav',)\n",
      "tensor([1]) ('Abuse_61.wav',)\n",
      "tensor([1]) ('Abuse_865.wav',)\n",
      "tensor([0]) ('Abuse_916.wav',)\n",
      "tensor([1]) ('Abuse_591.wav',)\n",
      "tensor([1]) ('Abuse_693.wav',)\n",
      "tensor([1]) ('Abuse_641.wav',)\n",
      "tensor([0]) ('Abuse_200.wav',)\n",
      "tensor([0]) ('Abuse_771.wav',)\n",
      "tensor([0]) ('Abuse_1086.wav',)\n",
      "tensor([1]) ('Abuse_139.wav',)\n",
      "tensor([1]) ('Abuse_736.wav',)\n",
      "tensor([0]) ('Abuse_245.wav',)\n",
      "tensor([0]) ('Abuse_1198.wav',)\n",
      "tensor([1]) ('Abuse_1111.wav',)\n",
      "tensor([0]) ('Abuse_506.wav',)\n",
      "tensor([0]) ('Abuse_552.wav',)\n",
      "tensor([0]) ('Abuse_871.wav',)\n",
      "tensor([0]) ('Abuse_1075.wav',)\n",
      "tensor([1]) ('Abuse_1085.wav',)\n",
      "tensor([1]) ('Abuse_913.wav',)\n",
      "tensor([1]) ('Abuse_93.wav',)\n",
      "tensor([1]) ('Abuse_559.wav',)\n",
      "tensor([0]) ('Abuse_939.wav',)\n",
      "tensor([1]) ('Abuse_830.wav',)\n",
      "tensor([1]) ('Abuse_751.wav',)\n",
      "tensor([0]) ('Abuse_212.wav',)\n",
      "tensor([1]) ('Abuse_1192.wav',)\n",
      "tensor([0]) ('Abuse_1108.wav',)\n",
      "tensor([0]) ('Abuse_853.wav',)\n",
      "tensor([0]) ('Abuse_1083.wav',)\n",
      "tensor([1]) ('Abuse_123.wav',)\n",
      "tensor([1]) ('Abuse_339.wav',)\n",
      "tensor([1]) ('Abuse_30.wav',)\n",
      "tensor([0]) ('Abuse_936.wav',)\n",
      "tensor([1]) ('Abuse_856.wav',)\n",
      "tensor([1]) ('Abuse_77.wav',)\n",
      "tensor([0]) ('Abuse_155.wav',)\n",
      "tensor([0]) ('Abuse_551.wav',)\n",
      "tensor([0]) ('Abuse_1137.wav',)\n",
      "tensor([1]) ('Abuse_78.wav',)\n",
      "tensor([0]) ('Abuse_873.wav',)\n",
      "tensor([1]) ('Abuse_497.wav',)\n",
      "tensor([0]) ('Abuse_1097.wav',)\n",
      "tensor([0]) ('Abuse_639.wav',)\n",
      "tensor([0]) ('Abuse_557.wav',)\n",
      "tensor([0]) ('Abuse_525.wav',)\n",
      "tensor([0]) ('Abuse_884.wav',)\n",
      "tensor([0]) ('Abuse_369.wav',)\n",
      "tensor([1]) ('Abuse_135.wav',)\n",
      "tensor([1]) ('Abuse_366.wav',)\n",
      "tensor([0]) ('Abuse_358.wav',)\n",
      "tensor([0]) ('Abuse_1069.wav',)\n",
      "tensor([0]) ('Abuse_1035.wav',)\n",
      "tensor([0]) ('Abuse_476.wav',)\n",
      "tensor([0]) ('Abuse_214.wav',)\n",
      "tensor([1]) ('Abuse_181.wav',)\n",
      "tensor([0]) ('Abuse_203.wav',)\n",
      "tensor([0]) ('Abuse_333.wav',)\n",
      "tensor([0]) ('Abuse_451.wav',)\n",
      "tensor([1]) ('Abuse_1168.wav',)\n",
      "tensor([0]) ('Abuse_1003.wav',)\n",
      "tensor([0]) ('Abuse_1178.wav',)\n",
      "tensor([0]) ('Abuse_404.wav',)\n",
      "tensor([1]) ('Abuse_45.wav',)\n",
      "tensor([1]) ('Abuse_362.wav',)\n",
      "tensor([0]) ('Abuse_1053.wav',)\n",
      "tensor([0]) ('Abuse_974.wav',)\n",
      "tensor([0]) ('Abuse_239.wav',)\n",
      "tensor([1]) ('Abuse_920.wav',)\n",
      "tensor([1]) ('Abuse_11.wav',)\n",
      "tensor([0]) ('Abuse_254.wav',)\n",
      "tensor([1]) ('Abuse_886.wav',)\n",
      "tensor([0]) ('Abuse_191.wav',)\n",
      "tensor([1]) ('Abuse_637.wav',)\n",
      "tensor([0]) ('Abuse_686.wav',)\n",
      "tensor([1]) ('Abuse_224.wav',)\n",
      "tensor([0]) ('Abuse_471.wav',)\n",
      "tensor([1]) ('Abuse_621.wav',)\n",
      "tensor([0]) ('Abuse_672.wav',)\n",
      "tensor([1]) ('Abuse_101.wav',)\n",
      "tensor([1]) ('Abuse_964.wav',)\n",
      "tensor([1]) ('Abuse_610.wav',)\n",
      "tensor([1]) ('Abuse_231.wav',)\n",
      "tensor([0]) ('Abuse_766.wav',)\n",
      "tensor([1]) ('Abuse_522.wav',)\n",
      "tensor([0]) ('Abuse_443.wav',)\n",
      "tensor([1]) ('Abuse_1145.wav',)\n",
      "tensor([1]) ('Abuse_229.wav',)\n",
      "tensor([0]) ('Abuse_403.wav',)\n",
      "tensor([0]) ('Abuse_1157.wav',)\n",
      "tensor([0]) ('Abuse_807.wav',)\n",
      "tensor([0]) ('Abuse_1116.wav',)\n",
      "tensor([0]) ('Abuse_263.wav',)\n",
      "tensor([1]) ('Abuse_1076.wav',)\n",
      "tensor([1]) ('Abuse_206.wav',)\n",
      "tensor([1]) ('Abuse_638.wav',)\n",
      "tensor([1]) ('Abuse_320.wav',)\n",
      "tensor([1]) ('Abuse_932.wav',)\n",
      "tensor([1]) ('Abuse_363.wav',)\n",
      "tensor([0]) ('Abuse_954.wav',)\n",
      "tensor([1]) ('Abuse_685.wav',)\n",
      "tensor([1]) ('Abuse_43.wav',)\n",
      "tensor([1]) ('Abuse_349.wav',)\n",
      "tensor([0]) ('Abuse_776.wav',)\n",
      "tensor([1]) ('Abuse_808.wav',)\n",
      "tensor([1]) ('Abuse_473.wav',)\n",
      "tensor([0]) ('Abuse_970.wav',)\n",
      "tensor([0]) ('Abuse_915.wav',)\n",
      "tensor([1]) ('Abuse_248.wav',)\n",
      "tensor([0]) ('Abuse_104.wav',)\n",
      "tensor([1]) ('Abuse_433.wav',)\n",
      "tensor([1]) ('Abuse_834.wav',)\n",
      "tensor([0]) ('Abuse_353.wav',)\n"
     ]
    }
   ],
   "source": [
    "#for hindi dataset\n",
    "\n",
    "labels=[]\n",
    "names=[]\n",
    "for batch_idx, (data, name, label) in enumerate(hindi_train_loader):\n",
    "\n",
    "\n",
    "    fromatted_data= data.cpu().detach().numpy().reshape(512, -1)\n",
    "    \n",
    "    # # For demonstration, let's stop after 5 batches\n",
    "    # if batch_idx >= 4:\n",
    "    #     break\n",
    "\n",
    "    labels.append(label.cpu().detach().numpy()[0])\n",
    "    names.append(name[0].split('.')[0]+'.npy')\n",
    "    print(label, name)\n",
    "\n",
    "    np.save('/home/ubuntu/Daniyal/profanity_detection/data/hindi_features/test/'+name[0].split('.')[0]+'.npy', fromatted_data)\n",
    "    # if batch_idx >= 4:\n",
    "    #     break\n",
    "\n",
    "np_csv = {\n",
    "    \"Name\": names,\n",
    "    \"Label\": labels\n",
    "}\n",
    "np_df = pd.DataFrame(np_csv)\n",
    "\n",
    "np_df.to_csv('/home/ubuntu/Daniyal/profanity_detection/data/hindi_features/train/hindi_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse_1197.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse_589.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abuse_327.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abuse_800.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abuse_1179.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Abuse_248.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Abuse_104.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Abuse_433.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Abuse_834.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Abuse_353.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Label\n",
       "0    Abuse_1197.npy      1\n",
       "1     Abuse_589.npy      0\n",
       "2     Abuse_327.npy      0\n",
       "3     Abuse_800.npy      0\n",
       "4    Abuse_1179.npy      0\n",
       "..              ...    ...\n",
       "364   Abuse_248.npy      1\n",
       "365   Abuse_104.npy      0\n",
       "366   Abuse_433.npy      1\n",
       "367   Abuse_834.npy      1\n",
       "368   Abuse_353.npy      0\n",
       "\n",
       "[369 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=pd.read_csv('/home/ubuntu/Daniyal/profanity_detection/data/hindi_features/test/hindi_test.csv')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profanity_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
