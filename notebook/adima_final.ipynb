{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn. functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim.lr_scheduler import LinearLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION= {'LEARNING_RATE': 0.001,\n",
    "                'EPOCHS': 50,\n",
    "                'ADAM_BETAS': (0.9, 0.999),\n",
    "                'ADAM_EPS': 1e-07,\n",
    "                'SEED': 42,\n",
    "                'BATCH_SIZE': 16,\n",
    "                'LINEAR_LR': False,\n",
    "                'DROPOUTS': 0.3,\n",
    "                'L2_REGULARISATION': 0.001\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: overwriting (reusing) task id=fc717fc84b9847dda38082a9dad51113\n",
      "ClearML results page: http://13.233.63.202:8080/projects/1d29852235204d9098563d5acdf7d416/experiments/fc717fc84b9847dda38082a9dad51113/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task, Logger\n",
    "\n",
    "task= Task.init(project_name='profanity_detection', task_name='adima_training_classifier3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LEARNING_RATE': 0.001,\n",
       " 'EPOCHS': 50,\n",
       " 'ADAM_BETAS': (0.9, 0.999),\n",
       " 'ADAM_EPS': 1e-07,\n",
       " 'SEED': 42,\n",
       " 'BATCH_SIZE': 16,\n",
       " 'LINEAR_LR': False,\n",
       " 'DROPOUTS': 0.3,\n",
       " 'L2_REGULARISATION': 0.001}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.connect(CONFIGURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(aud, shift_limit):\n",
    "    sig, sr = aud\n",
    "    _, sig_len = sig.shape\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "    return (sig.roll(shift_amt), sr)\n",
    "\n",
    "\n",
    "def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "        aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "        aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "    return aug_spec\n",
    "\n",
    "class AudioDataset (Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd. read_csv (csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "\n",
    "        file_path = os.path.join(self. root_dir, self.annotations. iloc[index, 0])\n",
    "        #print(file_path)\n",
    "        audio_feature= np.load(file_path)\n",
    "        \n",
    "        y_label = self .annotations. iloc [index, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            audio_feature = self.transform(audio_feature)\n",
    "        \n",
    "        audio_feature=torch.from_numpy(audio_feature)\n",
    "\n",
    "        audio_feature, sr = time_shift((audio_feature, 16000), 0.1)\n",
    "        audio_feature = audio_feature.unsqueeze(0)\n",
    "        audio_feature = spectro_augment(audio_feature, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "        audio_feature = audio_feature.squeeze()\n",
    "\n",
    "        max_pool, _ = torch.max(audio_feature, dim=1)\n",
    "\n",
    "        return (max_pool, y_label)\n",
    "    \n",
    "\n",
    "combined_dataset = AudioDataset (csv_file = str(Path.home())+'/Daniyal/profanity_detection/data/features/train_val_oversampled.csv', root_dir =str(Path.home())+ \"/Daniyal/profanity_detection/data/features/\")\n",
    "combined_loader = DataLoader (dataset=combined_dataset, batch_size=CONFIGURATION['BATCH_SIZE'], shuffle=True)#, sampler=train_sampler)\n",
    "\n",
    "\n",
    "test_dataset = AudioDataset (csv_file = str(Path.home())+'/Daniyal/profanity_detection/data/features/test/divided_test.csv', root_dir =str(Path.home())+ \"/Daniyal/profanity_detection/data/features/test/\")\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=CONFIGURATION['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = AudioDataset (csv_file = str(Path.home())+'/Daniyal/profanity_detection/data/features/test/divided_test.csv', root_dir =str(Path.home())+ \"/Daniyal/profanity_detection/data/features/test/\")\n",
    "val_loader = DataLoader (dataset=val_dataset, batch_size=CONFIGURATION['BATCH_SIZE'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential model\n",
    "class NN(nn.Module): #inherit n module\n",
    "    def __init__(self) :\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn. Linear (512, 256)\n",
    "        self.d1= nn. Dropout (p=CONFIGURATION['DROPOUTS'])\n",
    "        self. fc2 = nn. Linear (256, 128)\n",
    "        self.d2= nn. Dropout (p=0.1)\n",
    "        self. fc3 = nn. Linear (128, 2)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "\n",
    "\n",
    "    def forward (self, x):\n",
    "        x = F.gelu(self.fc1(x) ) \n",
    "        x = self.d2(F.gelu(self. fc2(x) ) )\n",
    "        x= self. fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (d1): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (d2): Dropout(p=0.1, inplace=False)\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model= NN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=CONFIGURATION['LEARNING_RATE'], \n",
    "                        betas=CONFIGURATION['ADAM_BETAS'], \n",
    "                        eps=CONFIGURATION['ADAM_EPS'], \n",
    "                        weight_decay=CONFIGURATION['L2_REGULARISATION'])\n",
    "scheduler = LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=50)\n",
    "\n",
    "train_accuracy_list=[]\n",
    "val_accuracy_list=[]\n",
    "train_precision_list=[]\n",
    "val_precision_list=[]\n",
    "train_recall_list=[]\n",
    "val_recall_list=[]\n",
    "loss_list=[]\n",
    "val_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/50\n",
      "Training: Epoch: 0, loss: 0.5928935404144117, train_accuracy: 0.67, train_precision:  0.65, train_recall:  0.73, train_f1_score: 0.66875, \n",
      "val_loss: 0.5346122036377589, val_accuracy: 0.69, val_precision:  0.53, val_recall:  0.90, val_f1_score: 0.688663282571912, lr: 0.001\n",
      "epoch: 2/50\n",
      "Training: Epoch: 1, loss: 0.5326707478779465, train_accuracy: 0.73, train_precision:  0.71, train_recall:  0.78, train_f1_score: 0.726622492916583, \n",
      "val_loss: 0.4803905685742696, val_accuracy: 0.73, val_precision:  0.57, val_recall:  0.84, val_f1_score: 0.721819061441703, lr: 0.001\n",
      "epoch: 3/50\n",
      "Training: Epoch: 2, loss: 0.5116511365370964, train_accuracy: 0.75, train_precision:  0.74, train_recall:  0.77, train_f1_score: 0.7498822425296352, \n",
      "val_loss: 0.5302209556102753, val_accuracy: 0.70, val_precision:  0.54, val_recall:  0.87, val_f1_score: 0.6978653530377668, lr: 0.001\n",
      "epoch: 4/50\n",
      "Training: Epoch: 3, loss: 0.4893513886786219, train_accuracy: 0.74, train_precision:  0.72, train_recall:  0.78, train_f1_score: 0.7390876271742698, \n",
      "val_loss: 0.4685029809673627, val_accuracy: 0.75, val_precision:  0.61, val_recall:  0.76, val_f1_score: 0.7362582575096597, lr: 0.001\n",
      "epoch: 5/50\n",
      "Training: Epoch: 4, loss: 0.4606656921443655, train_accuracy: 0.77, train_precision:  0.76, train_recall:  0.79, train_f1_score: 0.7697293447293447, \n",
      "val_loss: 0.5141783468425274, val_accuracy: 0.71, val_precision:  0.55, val_recall:  0.86, val_f1_score: 0.707384403036577, lr: 0.001\n",
      "epoch: 6/50\n",
      "Training: Epoch: 5, loss: 0.45566122967805434, train_accuracy: 0.77, train_precision:  0.76, train_recall:  0.80, train_f1_score: 0.7724209384139665, \n",
      "val_loss: 0.4866407898565133, val_accuracy: 0.73, val_precision:  0.57, val_recall:  0.86, val_f1_score: 0.7278353005101579, lr: 0.001\n",
      "epoch: 7/50\n",
      "Training: Epoch: 6, loss: 0.46140806666061057, train_accuracy: 0.77, train_precision:  0.75, train_recall:  0.81, train_f1_score: 0.7713725490196078, \n",
      "val_loss: 0.4510887774328391, val_accuracy: 0.77, val_precision:  0.64, val_recall:  0.78, val_f1_score: 0.7578947368421052, lr: 0.001\n",
      "epoch: 8/50\n",
      "Training: Epoch: 7, loss: 0.42285066353740974, train_accuracy: 0.81, train_precision:  0.78, train_recall:  0.85, train_f1_score: 0.8061550456334037, \n",
      "val_loss: 0.45447831228375435, val_accuracy: 0.77, val_precision:  0.66, val_recall:  0.70, val_f1_score: 0.7502262443438914, lr: 0.001\n",
      "epoch: 9/50\n",
      "Training: Epoch: 8, loss: 0.42548379235303224, train_accuracy: 0.80, train_precision:  0.79, train_recall:  0.82, train_f1_score: 0.8046403047119774, \n",
      "val_loss: 0.49287114664912224, val_accuracy: 0.77, val_precision:  0.61, val_recall:  0.90, val_f1_score: 0.761161590243608, lr: 0.001\n",
      "epoch: 10/50\n",
      "Training: Epoch: 9, loss: 0.3964341654261546, train_accuracy: 0.81, train_precision:  0.80, train_recall:  0.82, train_f1_score: 0.806541617589845, \n",
      "val_loss: 0.5030092063049475, val_accuracy: 0.77, val_precision:  0.63, val_recall:  0.78, val_f1_score: 0.7528040741087887, lr: 0.001\n",
      "epoch: 11/50\n",
      "Training: Epoch: 10, loss: 0.37669919364487947, train_accuracy: 0.81, train_precision:  0.80, train_recall:  0.84, train_f1_score: 0.814063402937125, \n",
      "val_loss: 0.6373175879319509, val_accuracy: 0.67, val_precision:  0.51, val_recall:  0.90, val_f1_score: 0.6729470316388197, lr: 0.001\n",
      "epoch: 12/50\n",
      "Training: Epoch: 11, loss: 0.3741523510039742, train_accuracy: 0.83, train_precision:  0.81, train_recall:  0.85, train_f1_score: 0.8272771712563141, \n",
      "val_loss: 0.5985433993240198, val_accuracy: 0.75, val_precision:  0.79, val_recall:  0.37, val_f1_score: 0.6666666666666667, lr: 0.001\n",
      "epoch: 13/50\n",
      "Training: Epoch: 12, loss: 0.4006974347936573, train_accuracy: 0.81, train_precision:  0.80, train_recall:  0.82, train_f1_score: 0.806541617589845, \n",
      "val_loss: 0.569404756029447, val_accuracy: 0.76, val_precision:  0.79, val_recall:  0.41, val_f1_score: 0.6899509803921569, lr: 0.001\n",
      "epoch: 14/50\n",
      "Training: Epoch: 13, loss: 0.35253161525548393, train_accuracy: 0.83, train_precision:  0.82, train_recall:  0.84, train_f1_score: 0.8320539478181611, \n",
      "val_loss: 0.5387197708090147, val_accuracy: 0.68, val_precision:  0.53, val_recall:  0.52, val_f1_score: 0.6426008230452676, lr: 0.001\n",
      "epoch: 15/50\n",
      "Training: Epoch: 14, loss: 0.33510131433383744, train_accuracy: 0.86, train_precision:  0.85, train_recall:  0.88, train_f1_score: 0.8612435717625058, \n",
      "val_loss: 0.5491131742795309, val_accuracy: 0.74, val_precision:  0.65, val_recall:  0.54, val_f1_score: 0.7027667984189723, lr: 0.001\n",
      "epoch: 16/50\n",
      "Training: Epoch: 15, loss: 0.34771514316992974, train_accuracy: 0.85, train_precision:  0.84, train_recall:  0.86, train_f1_score: 0.8490222051303964, \n",
      "val_loss: 0.5205146210889021, val_accuracy: 0.74, val_precision:  0.68, val_recall:  0.48, val_f1_score: 0.6903355175994557, lr: 0.001\n",
      "epoch: 17/50\n",
      "Training: Epoch: 16, loss: 0.31524949465224994, train_accuracy: 0.86, train_precision:  0.84, train_recall:  0.89, train_f1_score: 0.8593286716027215, \n",
      "val_loss: 0.5585637005666891, val_accuracy: 0.71, val_precision:  0.55, val_recall:  0.81, val_f1_score: 0.70461911252461, lr: 0.001\n",
      "epoch: 18/50\n",
      "Training: Epoch: 17, loss: 0.3369813670418156, train_accuracy: 0.85, train_precision:  0.84, train_recall:  0.87, train_f1_score: 0.8499293455177812, \n",
      "val_loss: 0.6428219315906366, val_accuracy: 0.74, val_precision:  0.76, val_recall:  0.35, val_f1_score: 0.6521739130434783, lr: 0.001\n",
      "epoch: 19/50\n",
      "Training: Epoch: 18, loss: 0.3323833137305815, train_accuracy: 0.85, train_precision:  0.84, train_recall:  0.85, train_f1_score: 0.8471611056521553, \n",
      "val_loss: 0.6149831966807445, val_accuracy: 0.75, val_precision:  0.63, val_recall:  0.65, val_f1_score: 0.7244791666666667, lr: 0.001\n",
      "epoch: 20/50\n",
      "Training: Epoch: 19, loss: 0.27247044043754465, train_accuracy: 0.88, train_precision:  0.88, train_recall:  0.89, train_f1_score: 0.8839613346849521, \n",
      "val_loss: 0.6379797781507174, val_accuracy: 0.74, val_precision:  0.60, val_recall:  0.73, val_f1_score: 0.7233082706766918, lr: 0.001\n",
      "epoch: 21/50\n",
      "Training: Epoch: 20, loss: 0.27280792110224267, train_accuracy: 0.88, train_precision:  0.88, train_recall:  0.89, train_f1_score: 0.8830151197439576, \n",
      "val_loss: 0.49528321623802185, val_accuracy: 0.76, val_precision:  0.65, val_recall:  0.65, val_f1_score: 0.7344877344877345, lr: 0.001\n",
      "epoch: 22/50\n",
      "Training: Epoch: 21, loss: 0.24648413907236127, train_accuracy: 0.90, train_precision:  0.89, train_recall:  0.90, train_f1_score: 0.8952754693067051, \n",
      "val_loss: 0.6762015670537949, val_accuracy: 0.72, val_precision:  0.60, val_recall:  0.57, val_f1_score: 0.688601294176207, lr: 0.001\n",
      "epoch: 23/50\n",
      "Training: Epoch: 22, loss: 0.2858387188457731, train_accuracy: 0.88, train_precision:  0.88, train_recall:  0.89, train_f1_score: 0.8839497667513144, \n",
      "val_loss: 0.6247969903051853, val_accuracy: 0.72, val_precision:  0.61, val_recall:  0.52, val_f1_score: 0.6804576565532741, lr: 0.001\n",
      "epoch: 24/50\n",
      "Training: Epoch: 23, loss: 0.27433358377485134, train_accuracy: 0.87, train_precision:  0.87, train_recall:  0.88, train_f1_score: 0.8735736537605696, \n",
      "val_loss: 0.5415283342202505, val_accuracy: 0.76, val_precision:  0.65, val_recall:  0.62, val_f1_score: 0.7252364360378298, lr: 0.001\n",
      "epoch: 25/50\n",
      "Training: Epoch: 24, loss: 0.2372114962495085, train_accuracy: 0.90, train_precision:  0.90, train_recall:  0.90, train_f1_score: 0.8981128448303484, \n",
      "val_loss: 0.5162455836931864, val_accuracy: 0.74, val_precision:  0.64, val_recall:  0.59, val_f1_score: 0.7106434235620838, lr: 0.001\n",
      "epoch: 26/50\n",
      "Training: Epoch: 25, loss: 0.21931765712241627, train_accuracy: 0.90, train_precision:  0.89, train_recall:  0.92, train_f1_score: 0.9028155712277834, \n",
      "val_loss: 0.7313508863250414, val_accuracy: 0.70, val_precision:  0.54, val_recall:  0.75, val_f1_score: 0.6848929663608563, lr: 0.001\n",
      "epoch: 27/50\n",
      "Training: Epoch: 26, loss: 0.2323946670920991, train_accuracy: 0.90, train_precision:  0.89, train_recall:  0.92, train_f1_score: 0.9009235562479136, \n",
      "val_loss: 0.7583587166542808, val_accuracy: 0.72, val_precision:  0.58, val_recall:  0.63, val_f1_score: 0.6928608115048793, lr: 0.001\n",
      "epoch: 28/50\n",
      "Training: Epoch: 27, loss: 0.20855917664828585, train_accuracy: 0.92, train_precision:  0.93, train_recall:  0.91, train_f1_score: 0.9198078235878924, \n",
      "val_loss: 0.6070377826690674, val_accuracy: 0.74, val_precision:  0.67, val_recall:  0.49, val_f1_score: 0.6936700789911799, lr: 0.001\n",
      "epoch: 29/50\n",
      "Training: Epoch: 28, loss: 0.2052733371340072, train_accuracy: 0.91, train_precision:  0.91, train_recall:  0.91, train_f1_score: 0.9113204390190068, \n",
      "val_loss: 0.7147072926163673, val_accuracy: 0.72, val_precision:  0.64, val_recall:  0.43, val_f1_score: 0.6601846822379142, lr: 0.001\n",
      "epoch: 30/50\n",
      "Training: Epoch: 29, loss: 0.19438833773914557, train_accuracy: 0.92, train_precision:  0.93, train_recall:  0.91, train_f1_score: 0.9198055395591886, \n",
      "val_loss: 1.0677459761500359, val_accuracy: 0.75, val_precision:  0.58, val_recall:  0.94, val_f1_score: 0.74701099952176, lr: 0.001\n",
      "epoch: 31/50\n",
      "Training: Epoch: 30, loss: 0.1870883037683679, train_accuracy: 0.91, train_precision:  0.90, train_recall:  0.93, train_f1_score: 0.912235953345637, \n",
      "val_loss: 0.7843243132034937, val_accuracy: 0.74, val_precision:  0.66, val_recall:  0.49, val_f1_score: 0.6887949260042283, lr: 0.001\n",
      "epoch: 32/50\n",
      "Training: Epoch: 31, loss: 0.1736457444894225, train_accuracy: 0.92, train_precision:  0.92, train_recall:  0.93, train_f1_score: 0.9245215843346685, \n",
      "val_loss: 0.818572498857975, val_accuracy: 0.72, val_precision:  0.60, val_recall:  0.51, val_f1_score: 0.6726874657909141, lr: 0.001\n",
      "epoch: 33/50\n",
      "Training: Epoch: 32, loss: 0.17822978951370538, train_accuracy: 0.93, train_precision:  0.93, train_recall:  0.94, train_f1_score: 0.9349028215007597, \n",
      "val_loss: 0.6897781975567341, val_accuracy: 0.71, val_precision:  0.57, val_recall:  0.60, val_f1_score: 0.6788623141564318, lr: 0.001\n",
      "epoch: 34/50\n",
      "Training: Epoch: 33, loss: 0.15410706220166898, train_accuracy: 0.94, train_precision:  0.94, train_recall:  0.95, train_f1_score: 0.9415075598719789, \n",
      "val_loss: 0.8378145284950733, val_accuracy: 0.74, val_precision:  0.70, val_recall:  0.44, val_f1_score: 0.6831654149111559, lr: 0.001\n",
      "epoch: 35/50\n",
      "Training: Epoch: 34, loss: 0.1383101902763123, train_accuracy: 0.94, train_precision:  0.94, train_recall:  0.95, train_f1_score: 0.9424523692340006, \n",
      "val_loss: 0.8952443525195122, val_accuracy: 0.73, val_precision:  0.67, val_recall:  0.41, val_f1_score: 0.6609169983782986, lr: 0.001\n",
      "epoch: 36/50\n",
      "Training: Epoch: 35, loss: 0.15284098829351253, train_accuracy: 0.94, train_precision:  0.94, train_recall:  0.94, train_f1_score: 0.939622641509434, \n",
      "val_loss: 0.8938525840640068, val_accuracy: 0.73, val_precision:  0.60, val_recall:  0.68, val_f1_score: 0.7133683039262438, lr: 0.001\n",
      "epoch: 37/50\n",
      "Training: Epoch: 36, loss: 0.14265233981631584, train_accuracy: 0.94, train_precision:  0.93, train_recall:  0.95, train_f1_score: 0.9367878958878311, \n",
      "val_loss: 0.9228125140070915, val_accuracy: 0.68, val_precision:  0.53, val_recall:  0.62, val_f1_score: 0.6569659051410877, lr: 0.001\n",
      "epoch: 38/50\n",
      "Training: Epoch: 37, loss: 0.1413532035119498, train_accuracy: 0.94, train_precision:  0.93, train_recall:  0.94, train_f1_score: 0.9367910464365975, \n",
      "val_loss: 0.9973689094185829, val_accuracy: 0.68, val_precision:  0.53, val_recall:  0.78, val_f1_score: 0.6773101112723754, lr: 0.001\n",
      "epoch: 39/50\n",
      "Training: Epoch: 38, loss: 0.14465284339193976, train_accuracy: 0.94, train_precision:  0.93, train_recall:  0.95, train_f1_score: 0.9405570969645666, \n",
      "val_loss: 0.7116758674383163, val_accuracy: 0.74, val_precision:  0.63, val_recall:  0.62, val_f1_score: 0.7152921810699588, lr: 0.001\n",
      "epoch: 40/50\n",
      "Training: Epoch: 39, loss: 0.1446143851559887, train_accuracy: 0.95, train_precision:  0.94, train_recall:  0.95, train_f1_score: 0.9452812656866898, \n",
      "val_loss: 1.0751226171851158, val_accuracy: 0.68, val_precision:  0.53, val_recall:  0.73, val_f1_score: 0.6736391437308868, lr: 0.001\n",
      "epoch: 41/50\n",
      "Training: Epoch: 40, loss: 0.13728014207375583, train_accuracy: 0.94, train_precision:  0.94, train_recall:  0.94, train_f1_score: 0.9405655616679023, \n",
      "val_loss: 0.7930440579851469, val_accuracy: 0.71, val_precision:  0.59, val_recall:  0.52, val_f1_score: 0.6708852215585029, lr: 0.001\n",
      "epoch: 42/50\n",
      "Training: Epoch: 41, loss: 0.11438661014466588, train_accuracy: 0.96, train_precision:  0.95, train_recall:  0.96, train_f1_score: 0.9556571806974337, \n",
      "val_loss: 0.8329833820462227, val_accuracy: 0.76, val_precision:  0.66, val_recall:  0.60, val_f1_score: 0.7229564693679527, lr: 0.001\n",
      "epoch: 43/50\n",
      "Training: Epoch: 42, loss: 0.12714330859676892, train_accuracy: 0.95, train_precision:  0.96, train_recall:  0.94, train_f1_score: 0.9518816106042035, \n",
      "val_loss: 0.8556946888566017, val_accuracy: 0.71, val_precision:  0.57, val_recall:  0.62, val_f1_score: 0.6810477657935285, lr: 0.001\n",
      "epoch: 44/50\n",
      "Training: Epoch: 43, loss: 0.14260638717895568, train_accuracy: 0.95, train_precision:  0.95, train_recall:  0.95, train_f1_score: 0.9471696232453658, \n",
      "val_loss: 0.8495320156216621, val_accuracy: 0.71, val_precision:  0.56, val_recall:  0.75, val_f1_score: 0.6998183888940191, lr: 0.001\n",
      "epoch: 45/50\n",
      "Training: Epoch: 44, loss: 0.10402152710246729, train_accuracy: 0.96, train_precision:  0.96, train_recall:  0.96, train_f1_score: 0.9613207202925599, \n",
      "val_loss: 0.7968036259214083, val_accuracy: 0.74, val_precision:  0.63, val_recall:  0.57, val_f1_score: 0.7032258064516128, lr: 0.001\n",
      "epoch: 46/50\n",
      "Training: Epoch: 45, loss: 0.08909217800611435, train_accuracy: 0.97, train_precision:  0.96, train_recall:  0.97, train_f1_score: 0.9650943085567003, \n",
      "val_loss: 1.0410236200938623, val_accuracy: 0.72, val_precision:  0.59, val_recall:  0.62, val_f1_score: 0.6956310207258928, lr: 0.001\n",
      "epoch: 47/50\n",
      "Training: Epoch: 46, loss: 0.17400080300589552, train_accuracy: 0.93, train_precision:  0.92, train_recall:  0.94, train_f1_score: 0.9273475629566925, \n",
      "val_loss: 0.7942616989215215, val_accuracy: 0.75, val_precision:  0.67, val_recall:  0.54, val_f1_score: 0.7076944329327255, lr: 0.001\n",
      "epoch: 48/50\n",
      "Training: Epoch: 47, loss: 0.11116791267726403, train_accuracy: 0.96, train_precision:  0.95, train_recall:  0.97, train_f1_score: 0.9584882015351532, \n",
      "val_loss: 0.9358273148536682, val_accuracy: 0.70, val_precision:  0.57, val_recall:  0.54, val_f1_score: 0.6641778662684585, lr: 0.001\n",
      "epoch: 49/50\n",
      "Training: Epoch: 48, loss: 0.0930928737620142, train_accuracy: 0.97, train_precision:  0.96, train_recall:  0.97, train_f1_score: 0.9650935629575239, \n",
      "val_loss: 1.2282009050250053, val_accuracy: 0.68, val_precision:  0.55, val_recall:  0.43, val_f1_score: 0.6277901785714286, lr: 0.001\n",
      "epoch: 50/50\n",
      "Training: Epoch: 49, loss: 0.10330860805697739, train_accuracy: 0.96, train_precision:  0.97, train_recall:  0.95, train_f1_score: 0.9622620013955939, \n",
      "val_loss: 0.8691775798797607, val_accuracy: 0.73, val_precision:  0.65, val_recall:  0.49, val_f1_score: 0.6839485399796683, lr: 0.001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(CONFIGURATION['EPOCHS']):\n",
    "  model.train()\n",
    "\n",
    "  print(f\"epoch: {epoch+1}/{CONFIGURATION['EPOCHS']}\")\n",
    "  \n",
    "  pred=torch.tensor([]).to(device=device)\n",
    "  label=torch.tensor([]).to(device=device)\n",
    "  running_loss = 0.0\n",
    "\n",
    "  for batch_idx, (data, targets) in enumerate(combined_loader):\n",
    "\n",
    "    data = data.to(device=device)\n",
    "    targets = targets.to(device=device)\n",
    "\n",
    "    data = data.reshape (data.shape [0], -1)\n",
    "\n",
    "    scores = model(data)\n",
    "    loss = criterion(scores, targets) \n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    _, prediction = torch.max(scores, 1)\n",
    "    pred=torch.cat([pred, prediction])\n",
    "    label=torch.cat([label, targets])\n",
    "\n",
    "  num_batches = len(combined_loader)\n",
    "  avg_loss = running_loss / num_batches\n",
    "\n",
    "  loss_list.append(avg_loss)\n",
    "\n",
    "\n",
    "  train_acc=accuracy_score(label.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "  train_accuracy_list.append(train_acc)\n",
    "  train_precision= precision_score(label.cpu().detach().numpy(), pred.cpu().detach().numpy(), zero_division=0, pos_label=1)\n",
    "  train_precision_list.append(train_precision)\n",
    "  train_recall=recall_score(label.cpu().detach().numpy(), pred.cpu().detach().numpy(), pos_label=1)\n",
    "  train_recall_list.append(train_recall)\n",
    "  macro_f1=f1_score(label.cpu().detach().numpy(), pred.cpu().detach().numpy(), average='macro')\n",
    "\n",
    "  #print(f'Training: Epoch: {epoch}, loss: {avg_loss:.2f}, train_accuracy: {accuracy(pred, label):.2f}, train_precision: {precision(pred, label): .2f}, train_recall: {recall(pred, label): .2f},')\n",
    "  print(f'Training: Epoch: {epoch}, loss: {avg_loss}, train_accuracy: {train_acc:.2f}, train_precision: {train_precision: .2f}, train_recall: {train_recall: .2f}, train_f1_score: {macro_f1}, ')\n",
    "\n",
    "\n",
    "  val_pred=torch.tensor([]).to(device=device)\n",
    "  val_label=torch.tensor([]).to(device=device)\n",
    "  val_running_loss = 0.0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad(): \n",
    "    for batch_idx, (data, targets) in enumerate(val_loader):\n",
    "\n",
    "      data = data.to(device=device)\n",
    "      targets = targets.to(device=device)\n",
    "\n",
    "      #data = data.reshape (data.shape [0], -1)\n",
    "\n",
    "      scores = model(data)\n",
    "      val_loss = criterion(scores, targets)\n",
    "      val_running_loss += val_loss.item()\n",
    "\n",
    "      _, prediction = torch.max(scores, 1)\n",
    "\n",
    "      val_pred=torch.cat([val_pred, prediction])\n",
    "      val_label=torch.cat([val_label, targets])\n",
    "\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    avg_val_loss = val_running_loss / num_val_batches\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "\n",
    "    val_acc=accuracy_score(val_label.cpu().detach().numpy(), val_pred.cpu().detach().numpy() )\n",
    "    val_accuracy_list.append(val_acc)\n",
    "    val_precision=precision_score(val_label.cpu().detach().numpy(), val_pred.cpu().detach().numpy(), zero_division=0, pos_label=1 )\n",
    "    val_precision_list.append(val_precision)\n",
    "    val_recall=recall_score(val_label.cpu().detach().numpy(), val_pred.cpu().detach().numpy(), pos_label=1 )\n",
    "    val_recall_list.append(val_recall)\n",
    "    macro_f1 = f1_score(val_label.cpu().detach().numpy(), val_pred.cpu().detach().numpy(), average='macro')\n",
    "\n",
    "    #print(f'val_accuracy: {accuracy(val_pred, val_label):.2f}, val_precision: {precision(val_pred, val_label): .2f}, val_recall: {recall(val_pred, val_label): .2f},')\n",
    "    print(f\"val_loss: {avg_val_loss}, val_accuracy: {val_acc:.2f}, val_precision: {val_precision: .2f}, val_recall: {val_recall: .2f}, val_f1_score: {macro_f1}, lr: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "  Logger.current_logger().report_scalar(\"Loss\", \"train\", iteration=epoch, value=avg_loss)\n",
    "  Logger.current_logger().report_scalar(\"Loss\", \"val\", iteration=epoch, value=avg_val_loss)\n",
    "  Logger.current_logger().report_scalar(\"Accuracy\", \"train\", iteration=epoch, value=train_acc)\n",
    "  Logger.current_logger().report_scalar(\"Accuracy\", \"val\", iteration=epoch, value=val_acc)\n",
    "  Logger.current_logger().report_scalar(\"Precision\", \"train\", iteration=epoch, value=train_precision)\n",
    "  Logger.current_logger().report_scalar(\"Precision\", \"val\", iteration=epoch, value=val_precision)\n",
    "  Logger.current_logger().report_scalar(\"Recall\", \"train\", iteration=epoch, value=train_recall)\n",
    "  Logger.current_logger().report_scalar(\"Recall\", \"val\", iteration=epoch, value=val_precision)\n",
    "\n",
    "  if CONFIGURATION['LINEAR_LR']:\n",
    "    scheduler.step()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y_%H%M\")\n",
    "\n",
    "torch.save(model.state_dict(),f'/home/ubuntu/Daniyal/work/model/model_trained_on_{dt_string}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.73, test_precision:  0.65, test_recall:  0.49\n"
     ]
    }
   ],
   "source": [
    "#test performance\n",
    "model.eval()\n",
    "test_pred=torch.tensor([]).to(device=device)\n",
    "test_label=torch.tensor([]).to(device=device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for batch_idx, (data, targets) in enumerate(test_loader):\n",
    "\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        scores = model(data)\n",
    "\n",
    "        _, prediction = torch.max(scores, 1)\n",
    "\n",
    "        test_pred=torch.cat([test_pred, prediction])\n",
    "        test_label=torch.cat([test_label, targets])\n",
    "\n",
    "    test_acc=accuracy_score(test_label.cpu().detach().numpy(), test_pred.cpu().detach().numpy() )\n",
    "    test_precision=precision_score(test_label.cpu().detach().numpy(), test_pred.cpu().detach().numpy(), zero_division=0 )\n",
    "    test_recall=recall_score(test_label.cpu().detach().numpy(), test_pred.cpu().detach().numpy() )\n",
    "\n",
    "    #print(f'val_accuracy: {accuracy(val_pred, val_label):.2f}, val_precision: {precision(val_pred, val_label): .2f}, val_recall: {recall(val_pred, val_label): .2f},')\n",
    "    print(f\"test_accuracy: {val_acc:.2f}, test_precision: {val_precision: .2f}, test_recall: {val_recall: .2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profanity_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
